{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"1\">Complex Networks - Practical Session 2</h1>\n",
    "<h3 style=\"text-align: center;\" markdown=\"1\">by Dimitri Lajou and Fabrice Lebeau</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we implement and illustrates two methods of constructing random graphs: the **Erdös-Rényi random graph model** and the **configuration model of random networks**. \n",
    "\n",
    "Let us first import the tools we are going to use and our own `Graph` class that we began to define in the last practical session. \n",
    "\n",
    "**Important note:** in order for our examples to be more interactive, we are using `ipywidgets`. You may have to allow this extension for Jupyter by executing the following command in a terminal:\n",
    "    \n",
    "    jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import scipy\n",
    "import scipy.special\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt;\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.rcParams['font.size'] = 14\n",
    "from IPython.display import Math, Markdown, Latex, display, display_latex, SVG\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" CR15 graph library \"\"\"\n",
    "class Graph(object):\n",
    "\n",
    "    def __init__(self, graph_dict={}, graph_name=\"\"):\n",
    "        \"\"\" initializes a graph object \"\"\"\n",
    "        self.__graph_dict = graph_dict.copy()\n",
    "        self.__name=graph_name\n",
    "\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "        \n",
    "    def vertices(self):\n",
    "        \"\"\" returns the vertices of a graph \"\"\"\n",
    "        return list(self.__graph_dict.keys())\n",
    "\n",
    "    def edges(self):\n",
    "        \"\"\" returns the edges of a graph \"\"\"\n",
    "        return self.__generate_edges()\n",
    "    \n",
    "    def connected_components(self):\n",
    "        return self.__generate_components()\n",
    "\n",
    "    def add_vertex(self, vertex):\n",
    "        \"\"\" If vertex is not in self.__graph_dict, a key \"vertex\" with an empty\n",
    "        list as a value is added to the dictionary. Otherwise nothing has to be \n",
    "        done.\"\"\"\n",
    "        if not vertex in self.__graph_dict:\n",
    "            self.__graph_dict[vertex] = []\n",
    "        \n",
    "\n",
    "    def add_edge(self, edge):\n",
    "        \"\"\" assumes that edge is of type set, tuple or list. No loops or \n",
    "        multiple edges.\"\"\"\n",
    "        my_edge = list(edge)\n",
    "        if len(my_edge) != 2: raise WrongSizeForEdge()\n",
    "        u = edge.pop()\n",
    "        v = edge.pop()\n",
    "        if u in self.__graph_dict and v in self.__graph_dict:\n",
    "            if u != v:\n",
    "                if v not in self.__graph_dict[u]:\n",
    "                    self.__graph_dict[u].append(v)\n",
    "                if u not in self.__graph_dict[v]:\n",
    "                    self.__graph_dict[v].append(u)\n",
    "        else:\n",
    "            raise VerticesNotDecleared()\n",
    "            \n",
    "\n",
    "    def __generate_edges(self):\n",
    "        \"\"\" A static method generating the edges of the graph \"graph\". Edges \n",
    "        are represented as sets two vertices, with no loops. To complete.\"\"\"\n",
    "        edges = []\n",
    "        for v, edges_list in self.__graph_dict.items():\n",
    "            for u in edges_list:\n",
    "                if v < u:\n",
    "                    edges.append(set([v,u]))\n",
    "        return edges\n",
    "    \n",
    "    def vertex_degrees(self):\n",
    "        \"\"\"Return a dictionary degree\"\"\"\n",
    "        degrees = {}\n",
    "        for v, edges_list in self.__graph_dict.items():\n",
    "            degrees[v] = len(edges_list)\n",
    "        return degrees\n",
    "    \n",
    "    def vertex_degree(self, vertex):\n",
    "        \"\"\"Return a dictionary degree\"\"\"\n",
    "        return len(self.__graph_dict[vertex])\n",
    "    \n",
    "    def find_isolated_vertices(self):\n",
    "        \"\"\"Return a set of zero-degree verticies\"\"\"\n",
    "        zero_set = set()\n",
    "        for v, edges_list in self.__graph_dict.items():\n",
    "            if len(edges_list) == 0:\n",
    "                zero_set.add(v)\n",
    "        return zero_set\n",
    "                \n",
    "    def density(self):\n",
    "        \"\"\"Return the density of the graph\"\"\"\n",
    "        deg = self.vertex_degrees()\n",
    "        density = 0\n",
    "        for v, d in deg.items():\n",
    "            density += d\n",
    "        density /=  (len(deg) -1) *len(deg)\n",
    "        return density\n",
    "                    \n",
    "    def dict(self):\n",
    "        return self.__graph_dict\n",
    "    \n",
    "    def degree_sequence(self):\n",
    "        \"\"\"Return the list of vertex degree sorted by decreasing degree\"\"\"\n",
    "        deg = self.vertex_degrees()\n",
    "        deg_list = [v for v in deg.values()]\n",
    "        deg_list.sort(reverse=True)\n",
    "        return tuple(deg_list)\n",
    "    \n",
    "    @staticmethod\n",
    "    def erdos_gallai(deg_seq):\n",
    "        \"\"\"Given a degree sequence, this method verify that this sequence verify the erdos gallai conditions\"\"\"\n",
    "        even_number = 0\n",
    "        for v in deg_seq:\n",
    "            even_number += v\n",
    "        if even_number % 2 == 1 :\n",
    "            return False\n",
    "        sumOfdi = 0\n",
    "        for k in range(len(deg_seq)):\n",
    "            sumOfdi += deg_seq[k]\n",
    "            sumOfMin = k*(k+1)\n",
    "            for i in range(k, len(deg_seq)):\n",
    "                sumOfMin += min(deg_seq[i], k+1)\n",
    "            if sumOfMin < sumOfdi:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def global_clustering_coefficient(self):\n",
    "        triangle = 0\n",
    "        triplet = 0\n",
    "        for v in self.__graph_dict:\n",
    "            for u in self.__graph_dict[v]:\n",
    "                for w in self.__graph_dict[v]:\n",
    "                    if u != w: \n",
    "                        triplet += 1\n",
    "                    if u != w and w in self.__graph_dict[u]:\n",
    "                        triangle += 1\n",
    "        return triangle / triplet\n",
    "    \n",
    "    \"\"\" Graph traversal \"\"\"\n",
    "    def components_BFS(self, vertices, comps, base_vertice):\n",
    "        if not vertices:\n",
    "            return\n",
    "        new_vertices = []\n",
    "        for v in vertices:\n",
    "            comps[v] = base_vertice\n",
    "            for u in self.__graph_dict[v]:\n",
    "                if comps[u] == u and u != base_vertice:\n",
    "                    new_vertices.append(u)\n",
    "        self.components_BFS(new_vertices, comps, base_vertice)\n",
    "    \n",
    "    def __generate_components(self):\n",
    "        \"\"\"Retuen a dictionnary of components representant\"\"\"\n",
    "        comps = {}\n",
    "        for u in self.__graph_dict:\n",
    "            comps[u] = u\n",
    "        for u in self.__graph_dict:\n",
    "            if comps[u] == u:\n",
    "                self.components_BFS([u], comps, u)\n",
    "        return comps\n",
    "    \n",
    "    def shortest_path_BFS(self, vertices, seen, d, goal):\n",
    "        if not vertices:\n",
    "            return math.inf\n",
    "        if goal in vertices:\n",
    "            return d\n",
    "        new_vertices = set()\n",
    "        for v in vertices:\n",
    "            seen.add(v)\n",
    "        for v in vertices:\n",
    "            for u in self.__graph_dict[v]:\n",
    "                if u not in seen:\n",
    "                    new_vertices.add(u)\n",
    "        return self.shortest_path_BFS(new_vertices, seen, d+1, goal)\n",
    "    \n",
    "    def shortest_path(self, s, t):\n",
    "        \"\"\"Return the shortest path between s and t\"\"\"\n",
    "        return self.shortest_path_BFS({s}, set(), 0, t)\n",
    "    \n",
    "    def diameter_BFS(self, vertices, seen, d):\n",
    "        if not vertices:\n",
    "            if d > 0:\n",
    "                return d-1\n",
    "            else:\n",
    "                return d\n",
    "        new_vertices = set()\n",
    "        for v in vertices:\n",
    "            seen.add(v)\n",
    "        for v in vertices:\n",
    "            for u in self.__graph_dict[v]:\n",
    "                if u not in seen:\n",
    "                    new_vertices.add(u)\n",
    "        return self.diameter_BFS(new_vertices, seen, d+1)\n",
    "    \n",
    "    def diameter(self):\n",
    "        diam = 0\n",
    "        for u in self.__graph_dict:\n",
    "            m = self.diameter_BFS({u}, set(), 0)\n",
    "            if (m > diam):\n",
    "                diam = m\n",
    "        return diam\n",
    "    \n",
    "    def diameter_component(self, u):\n",
    "        \"\"\" Return the diameter of the component containing vertex u \"\"\"\n",
    "        component = set()\n",
    "        comps = self.connected_components()\n",
    "        # First get the nodes of the component #\n",
    "        for v in self.__graph_dict:\n",
    "            if comps[v] == comps[u]:\n",
    "                component.add(v)\n",
    "        diam = 0\n",
    "        for v in component:\n",
    "            m = self.diameter_BFS({v}, set(), 0)\n",
    "            if (m > diam):\n",
    "                diam = m\n",
    "        return diam\n",
    "    \n",
    "    def biggest_component_diameter(self):\n",
    "        if not self.vertices(): return 0\n",
    "        \n",
    "        # First determine the biggest component #\n",
    "        comps = self.connected_components()\n",
    "        comps_size = {}\n",
    "        for u in comps.values():\n",
    "            comps_size[u] = 0\n",
    "        for v,u in comps.items():\n",
    "            comps_size[u] += 1\n",
    "        biggest = tuple(comps.values())[0]\n",
    "        max_size = comps_size[biggest]\n",
    "        for u in comps.values():\n",
    "            if comps_size[u] > max_size:\n",
    "                max_size = comps_size[u]\n",
    "                biggest = u\n",
    "        \n",
    "        # Return the diameter of the corresponding component\n",
    "        return self.diameter_component(biggest)\n",
    "        \n",
    "    def spanning_tree(self):\n",
    "        queue = []\n",
    "        tree = []\n",
    "        # Hack to get one key in the dict\n",
    "        for v in self.__graph_dict:\n",
    "            queue.append(v)\n",
    "            break\n",
    "        seen = [queue[-1]]\n",
    "\n",
    "        while queue:\n",
    "            u = queue.pop()\n",
    "            for v in self.__graph_dict[u]:\n",
    "                if not v in seen:\n",
    "                    tree.append(set([u,v]))\n",
    "                    seen.append(v)\n",
    "                    queue.append(v)\n",
    "        return tree\n",
    "    \n",
    "    def irregular_edge_count(self):\n",
    "        nb_loop = 0\n",
    "        nb_multi = 0\n",
    "        nb_edge = 0\n",
    "        for v in self.__graph_dict:\n",
    "            seen = []\n",
    "            for u in self.__graph_dict[v]:\n",
    "                nb_edge += 1\n",
    "                if u == v:\n",
    "                    nb_loop += 1\n",
    "                elif u in seen:\n",
    "                    nb_multi += 1\n",
    "                else:\n",
    "                    seen.append(u)\n",
    "        return (nb_loop + nb_multi // 2) / nb_edge * 2\n",
    "        \n",
    "    \"\"\" Static methods for defining classical graphs \"\"\"\n",
    "    @staticmethod\n",
    "    def clique(n):\n",
    "        d = {}\n",
    "        s = set(i+1 for i in range(n))\n",
    "        for i in range(n):\n",
    "            d[i+1] = s.difference(set({i+1}))\n",
    "        return Graph(d,\"$K_\"+str(n)+\"$\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def no_edges(n):\n",
    "        d = {}\n",
    "        for i in range(n):\n",
    "            d[i+1] = []\n",
    "        return Graph(d,\"$D_\"+str(n)+\"$\")\n",
    "\n",
    "    \"\"\" Importing from a text file \"\"\"\n",
    "    @staticmethod\n",
    "    def from_txt(file):\n",
    "        G = Graph()\n",
    "        lines = open(file).readlines()\n",
    "        for l in lines:\n",
    "            p = parse('{:d}\\t{:d}', l)\n",
    "            G.add_vertex(p[0])\n",
    "            G.add_vertex(p[1])\n",
    "            G.add_edge({p[0],p[1]})\n",
    "        return G\n",
    "    def print(self):\n",
    "        print(self.__graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Erdös-Rényi random graph model\n",
    "### Generating ER graphs\n",
    "We first implement the two variants that we are studying in this section:\n",
    "- the first one, in function `er_np`, returns a graph (drawn from set $G_{n,p}$) with the specified number of nodes $n$ and each couple of nodes is linked independently from the others with the given probability $p$;\n",
    "- the second one, in function `er_nm` returns a graph (drawn from set $G_{n,m}$) with the specified number of nodes $n$ and the exact given number of edges $m$ that are chosen uniformly among all possible edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def er_np(n, p):\n",
    "    graph_dict = {}\n",
    "    for i in range(n):\n",
    "        graph_dict[i] = []\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            rv = random.uniform(0,1)\n",
    "            if rv < p:\n",
    "                graph_dict[i].append(j)\n",
    "                graph_dict[j].append(i)  \n",
    "    return Graph(graph_dict)\n",
    "\n",
    "def er_nm(n, m):\n",
    "    graph_dict = {}\n",
    "    for i in range(n):\n",
    "        graph_dict[i] = []\n",
    "    # number of possible edges (*2 since it is easier to sample couple than pairs)\n",
    "    nb_possibility = n*n\n",
    "    count_left = m\n",
    "    if m > n*(n-1)/2 :\n",
    "        count_left = n*(n-1)/2\n",
    "    while count_left > 0:\n",
    "        # sample an index for the new edge\n",
    "        edge_ind = random.randrange(nb_possibility)\n",
    "        # get the two endpoints (part where it is easier for couple)\n",
    "        i = edge_ind // n\n",
    "        j = edge_ind % n\n",
    "        # handle loops and multiedges\n",
    "        if i == j :\n",
    "            continue \n",
    "        if j in graph_dict[i]:\n",
    "            continue\n",
    "        graph_dict[i].append(j)\n",
    "        graph_dict[j].append(i)\n",
    "        count_left -= 1\n",
    "    return Graph(graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of edges\n",
    "A graph drawn from set $G_{n,p}$ has an expected number of edges which is $$\\left\\lfloor p \\binom{n}{2} \\right\\rfloor.$$ We want to compare the number of edges obtained from graphs generated by our function `er_np` with the expected number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_edge_number(n, p):\n",
    "    return math.floor(p * n*(n-1)/2)\n",
    "\n",
    "def binomial_coef(n, k):\n",
    "    return scipy.special.binom(n, k)\n",
    "\n",
    "def compare_edge_count(n, p):\n",
    "    \"\"\"Generate an er_np graph and compare its edges to an er_nm\"\"\"\n",
    "    m = expected_edge_number(n, p)\n",
    "    G_tmp = er_np(n, p)\n",
    "    nb_edges = len(G_tmp.edges())\n",
    "    if m == 0:\n",
    "        m = 1\n",
    "    return nb_edges / m\n",
    "\n",
    "def compare_edge_counts(n):\n",
    "    x = [ p for p in np.arange(1/n, 1.0, 1/n)]\n",
    "    got = [ compare_edge_count(n, p) for p in  np.arange(1/n, 1.0, 1/n)]\n",
    "    plt.plot(x, got, label='Ratio |E| / $\\\\left\\\\lfloor p \\\\binom{n}{2} \\\\right\\\\rfloor$')\n",
    "    plt.axhline(1., ls='--', c='red')\n",
    "    plt.xlabel('$p$')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "w = interact(compare_edge_counts, n=widgets.IntSlider(description='$n$', min=1, max=200, step=1, value=100, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By playing a bit with the previous plot, we can make several observations:\n",
    "- most of the big differences between the number of edges and the expected value happen when $p$ is small;\n",
    "- we rarely observe a ratio greater than $1.1$ and smaller than $0.9$;\n",
    "- when $p$ is not small (typically $p \\geq 0.3$), we rarely observe a ratio greater than $1.05$ and smaller than $0.95$.\n",
    "\n",
    "From these experiments, the variant drawing a graph in $G_{n,p}$ which is simpler than the other one seems to be a rather good approximation of drawing a graph with $\\left\\lfloor p \\binom{n}{2} \\right\\rfloor$ edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree distribution\n",
    "We are now interested in the **degree distribution** of graphs in $G_{n,p}$. We know that the theoretical distribution of degrees in a graph in $G_{n,p}$ is a binomial law with parameter $n-1$ and $p$.\n",
    "We first plot the result for *one* graph generated with the `er_np` function, and we plot the corresponding binomial law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree distribution\n",
    "n = 1000\n",
    "p = .5\n",
    "def degree_distr_er_np(n, p):\n",
    "    graph_tmp = er_np(n, p)\n",
    "    got = [0 for k in range(n)]\n",
    "    for x in graph_tmp.vertex_degrees().values():\n",
    "        got[x] += 1\n",
    "    for k in range(n):\n",
    "        got[k] /= n\n",
    "    plt.plot(got, label='Measured')\n",
    "    expected = [binomial_coef(n-1, k) * math.pow(p, k) * math.pow(1-p, n-1-k) for k in range(n)]\n",
    "    plt.plot(expected, 'r--', label='$\\\\mathcal{B}(n-1,p)$')\n",
    "    plt.xlim(n*p - 0.5*n*p*(1-p), n*p + 0.5*n*p*(1-p))\n",
    "    plt.xlabel('Degree')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "w = interact(degree_distr_er_np, n=widgets.IntSlider(description='$n$',min=100,max=1000,step=10,value=700,continuous_update=False)\n",
    "                             , p=widgets.FloatSlider(description='$p$',min=0.1,max=0.9,step=0.01,value=0.5,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the degree distribution in graphs of $G_{n,p}$ *roughly* follows a binomial law. In particular, the values for which the probability are very close to 0 are the same, and when the probability is non-zero then it has very roughly the same shape. \n",
    "\n",
    "In order to smooth a little bit this curve, we make another plot where we take an average degree distribution over a small number of graphs.\n",
    "\n",
    "**Remark:** in nearly all the following experiments, we take an average over a small number of graphs (less than 20) in order to smooth the results. Since this number is small compared to the total number of possible graphs, it gives us a trend of what happens for most graph, as it is *very* unlikely that we observe a case where there have been a \"mean effect\" that flaws entirely the result of the experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 20\n",
    "\n",
    "def average_edge_distr_er_np(n, p):\n",
    "    got = [0 for k in range(n)]\n",
    "    for i in range(nb):\n",
    "        graph_tmp = er_np(n, p)\n",
    "        for x in graph_tmp.vertex_degrees().values():\n",
    "            got[x] += 1\n",
    "    for k in range(n):\n",
    "        got[k] /= n * nb\n",
    "    plt.plot(got, label='Average measured')\n",
    "    expected = [binomial_coef(n-1, k) * math.pow(p, k) * math.pow(1-p, n-1-k) for k in range(n)]\n",
    "    plt.plot(expected, 'r--', label='$\\\\mathcal{B}(n-1,p)$')\n",
    "    plt.xlim(n*p - 0.3*n*p*(1-p), n*p + 0.3*n*p*(1-p))\n",
    "    plt.xlabel('Degree')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "w = interact(average_edge_distr_er_np, n=widgets.IntSlider(description='$n$',min=100,max=1000,step=10,value=700,continuous_update=False)\n",
    "                             , p=widgets.FloatSlider(description='$p$',min=0.1,max=0.9,step=0.01,value=0.5,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very clear on this new plot that the degree distribution of graphs drawn from $G_{n,p}$ is close to a  binomial law with parameter $n-1$ and $p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected components\n",
    "We are now interested in the **connected components** of graphs in $G_{n,p}$. We implement a function `biggest_comp_size` that returns the size of the biggest component of a given graph, and `two_biggest_comp_size` that also returns the size of the second biggest component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biggest_comp_size(G):\n",
    "    comps = G.connected_components()\n",
    "    # First determine the biggest component #\n",
    "    comps_size = {}\n",
    "    for u in comps.values():\n",
    "        comps_size[u] = 0\n",
    "    for v,u in comps.items():\n",
    "        comps_size[u] += 1\n",
    "    biggest = tuple(comps.values())[0]\n",
    "    max_size = comps_size[biggest]\n",
    "    for u in comps.values():\n",
    "        if comps_size[u] > max_size:\n",
    "            max_size = comps_size[u]\n",
    "            biggest = u\n",
    "    return max_size\n",
    "def two_biggest_comp_size(G):\n",
    "    comps = G.connected_components()\n",
    "    # First determine the biggest component #\n",
    "    comps_size = {}\n",
    "    for u in comps.values():\n",
    "        comps_size[u] = 0\n",
    "    for v,u in comps.items():\n",
    "        comps_size[u] += 1\n",
    "    biggest = tuple(comps.values())[0]\n",
    "    max_size = comps_size[biggest]\n",
    "    for u in comps.values():\n",
    "        if comps_size[u] > max_size:\n",
    "            max_size = comps_size[u]\n",
    "            biggest = u\n",
    "    sec_size = 0\n",
    "    for u in comps.values():\n",
    "        if u == biggest:\n",
    "            continue\n",
    "        else:\n",
    "            if comps_size[u] > sec_size:\n",
    "                sec_size = comps_size[u]\n",
    "    return max_size, sec_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next plot, we fix some $n$ and see how the size of the biggest component, of the second biggest component, and the number of isolated vertices (i.e. vertices with degree 0) evolve with $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_average = 10\n",
    "\n",
    "def connected_components_er_np(n):\n",
    "    end_point = math.ceil(math.log(n,2)+1)\n",
    "    step = 20*end_point\n",
    "\n",
    "    bcomp_size = [0 for i in range(step)]\n",
    "    sec_size = [0 for i in range(step)]\n",
    "    isolated_size = [0 for i in range(step)]\n",
    "    x = [0 for i in range(step)]\n",
    "    for t in range(nb_average):\n",
    "        for i in range(step):\n",
    "            p = end_point * i / (step * n) \n",
    "            x[i] = n * p\n",
    "            G = er_np(n, p)\n",
    "            bcomp, sec = two_biggest_comp_size(G)\n",
    "            bcomp_size[i] += bcomp\n",
    "            sec_size[i] += sec\n",
    "            isolated_size[i] += len(G.find_isolated_vertices())\n",
    "    bcomp_size = [x / nb_average for x in bcomp_size]\n",
    "    sec_size = [x / nb_average for x in sec_size]\n",
    "    isolated_size = [x / nb_average for x in isolated_size]\n",
    "\n",
    "\n",
    "    plt.plot(x, bcomp_size, label='Biggest component')\n",
    "    plt.plot(x, sec_size, label='Second biggest component')\n",
    "    plt.plot(x, isolated_size, label='Isolated vertices')\n",
    "\n",
    "    #plt.axhline(math.pow(n, 2/3), ls = '--', c='red')\n",
    "    #plt.text(0., math.pow(n, 2/3)+0.01 * n, '$n^{2/3}$')\n",
    "\n",
    "    #plt.axvline(1, ls = '--', c = 'red')\n",
    "    plt.axhline(math.log(n,2), ls='--', c='red')\n",
    "    plt.text(math.log(n,2)-0.1*math.log(n,2), math.log(n,2)+0.01 * n, '$\\log\\ n$')\n",
    "\n",
    "    plt.axvline(math.log(n, 2), ls = '--', c = 'red')\n",
    "    plt.text(math.log(n,2) - 0.03 * end_point ,n/2,'$\\log\\ n$',rotation=90)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('$np$')\n",
    "    plt.show()\n",
    "    \n",
    "w = interact(connected_components_er_np, n=widgets.IntSlider(description='$n$',min=10,max=200,value=100,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the value of $n$, we can remark an important fact: when $np$ is greater than $\\log n$, the size of the biggest component is almost equal to $n$, i.e. the graph is almost surely connected (the difference is less than 1 when we take the average). We cannot draw a lot of other conclusions from this graph since we need to draw the values as a function of $n$ and here we fixed $n$.\n",
    "\n",
    "In the next plot, we fix some constant $c>0$ and we draw the size of the biggest component and when it is interesting the size of the second biggest component as a function of $n$, the probability parameter for the random graph generation being $$p=\\frac{c}{n}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = c/n with different values of c and let n go big\n",
    "nb_average = 20\n",
    "\n",
    "def connected_components_er_np_bis(c, n_max):\n",
    "    # Determine minimum n such that c/n < 1\n",
    "    n_min = math.ceil(c)\n",
    "    bcomp_size = [0 for i in range(n_min,n_max+1)]\n",
    "    if c > 1.:\n",
    "        sec_size = [0 for i in range(n_min,n_max+1)]\n",
    "    x = [i for i in range(n_min,n_max+1)]\n",
    "    for t in range(nb_average):\n",
    "        for n in range(n_min,n_max+1):\n",
    "            G = er_np(n, c/n)\n",
    "            if c > 1.:\n",
    "                bcomp, sec = two_biggest_comp_size(G)\n",
    "                bcomp_size[n-n_min] += bcomp\n",
    "                sec_size[n-n_min] += sec\n",
    "            else:\n",
    "                bcomp = biggest_comp_size(G)\n",
    "                bcomp_size[n-n_min] += bcomp\n",
    "    bcomp_size = [x / nb_average for x in bcomp_size]\n",
    "    if c > 1.:\n",
    "        sec_size = [x / nb_average for x in sec_size]\n",
    "    \n",
    "    plt.plot(x, bcomp_size, label='Biggest component')\n",
    "    if c > 1.:\n",
    "        plt.plot(x, sec_size, label='Second biggest')\n",
    "    \n",
    "    # Draw hypothesis according to constant c\n",
    "    if c == 1.:\n",
    "        hyp = [math.pow(n,2/3) for n in range(n_min, n_max+1)]\n",
    "        plt.plot(x, hyp, 'r--', label='$n^{2/3}$')\n",
    "    elif c<1.:\n",
    "        # Doing a logarithm fit for the biggest component when c>1\n",
    "        log_fit = np.polyfit(np.log(x), bcomp_size, 1)\n",
    "        hyp = [log_fit[0]*math.log(n)+log_fit[1] for n in range(n_min, n_max+1)]\n",
    "        op = ''\n",
    "        if (log_fit[1] > 0):\n",
    "            op = '+'\n",
    "        plt.plot(x, hyp, 'r--', label='$'+str(round(log_fit[0],2))+'\\ \\log\\ x'+op+str(round(log_fit[1],2))+'$')\n",
    "    else:\n",
    "        # Doing a logarithm fit for the biggest component when c>1\n",
    "        log_fit = np.polyfit(np.log(x), sec_size, 1)\n",
    "        hyp = [log_fit[0]*math.log(n)+log_fit[1] for n in range(n_min, n_max+1)]\n",
    "        op = ''\n",
    "        if (log_fit[1] > 0):\n",
    "            op = '+'\n",
    "        plt.plot(x, hyp, 'r--', label='$'+str(round(log_fit[0],2))+'\\ \\log\\ x'+op+str(round(log_fit[1],2))+'$')\n",
    "        lin_fit = np.polyfit(x, bcomp_size, 1)\n",
    "        hyp2 = [lin_fit[0] * n + lin_fit[1] for n in range(n_min, n_max+1)]\n",
    "        op = ''\n",
    "        if (lin_fit[1] > 0):\n",
    "            op = '+'\n",
    "        plt.plot(x, hyp2, 'g--', label='$'+str(round(lin_fit[0],2))+'x'+op+str(round(lin_fit[1],2))+'$')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('$n$')\n",
    "    plt.show()\n",
    "    \n",
    "w = interact(connected_components_er_np_bis, n_max=widgets.IntSlider(description='$n_\\\\text{max}$',min=10,max=200,value=130,step=5,continuous_update=False)\n",
    "                                           , c=widgets.FloatSlider(description='$c$',min=0.1,max=2.,value=1.,step=0.05,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three cases that we observe in this plot:\n",
    "- when $c=1$: the biggest component has a size which is close to the function $n^{2/3}$;\n",
    "- when $c<1$: the biggest component has a size which is logarithmic as a function of $n$;\n",
    "- when $c>1$: the biggest component has a size which is linear (i.e. there is a positive fraction of the nodes in the component) and the second biggest component has logarithmic size.\n",
    "\n",
    "These results corresponds to the well-known characteristics of ER graphs proved by Erdös and Rényi in 1960."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The configuration model of random networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "def degree_sequence_regular(n, k):\n",
    "    return [k for i in range(n)]\n",
    "\n",
    "def degree_sequence_lognormal(n, mu, sigma):\n",
    "    return [max(0, math.floor(np.random.lognormal(mu, sigma))) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def configure_sequence(seq):\n",
    "    non_zero_idx = [ i for i in range(len(seq))]\n",
    "    \n",
    "    G = {}\n",
    "    for i in range(len(seq)):\n",
    "        G[i] = []\n",
    "    \n",
    "    while len(non_zero_idx) > 0:\n",
    "        id1 = non_zero_idx[random.randrange(len(non_zero_idx))] #get first stubs\n",
    "        has_removed_1 = False\n",
    "        if seq[id1] > 1:\n",
    "            seq[id1] -= 1\n",
    "        elif seq[id1] == 1:\n",
    "            seq[id1] = 0\n",
    "            has_removed_1 = True\n",
    "            non_zero_idx.remove(id1)\n",
    "        else:\n",
    "            has_removed_1 = True\n",
    "            non_zero_idx.remove(id1)\n",
    "        \n",
    "        if len(non_zero_idx) == 0:\n",
    "            continue\n",
    "        \n",
    "        id2 = non_zero_idx[random.randrange(len(non_zero_idx))] #get 2nd stubs\n",
    "        if seq[id2] > 1:\n",
    "            seq[id2] -= 1\n",
    "        elif seq[id2] == 1:\n",
    "            seq[id2] = 0\n",
    "            non_zero_idx.remove(id2)\n",
    "        elif not has_removed_1 and len(non_zero_idx) == 1:\n",
    "            break\n",
    "        else:\n",
    "            if has_removed_1:\n",
    "                non_zero_idx.append(id1)\n",
    "            seq[id1] += 1\n",
    "            continue\n",
    "            \n",
    "        G[id1].append(id2)\n",
    "        G[id2].append(id1)\n",
    "        \n",
    "    return Graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_min = 10\n",
    "n_max = 500\n",
    "step = 5\n",
    "k = 20\n",
    "\n",
    "nb_sample = (n_max - n_min) // step\n",
    "irregular = [ 0 for i in range(nb_sample)]\n",
    "x = [ 0 for i in range(nb_sample)]\n",
    "for i in range(nb_sample):\n",
    "    x[i] = n_min + i * step\n",
    "    irregular[i] = configure_sequence(degree_sequence_regular(x[i], k)).irregular_edge_count()\n",
    "    \n",
    "plt.plot(x, irregular)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_min = 10\n",
    "n_max = 500\n",
    "step = 2\n",
    "mu = 2\n",
    "sigma = 1\n",
    "\n",
    "nb_sample = (n_max - n_min) // step\n",
    "irregular = [ 0 for i in range(nb_sample)]\n",
    "x = [ 0 for i in range(nb_sample)]\n",
    "for i in range(nb_sample):\n",
    "    x[i] = n_min + i * step\n",
    "    irregular[i] = configure_sequence(degree_sequence_lognormal(x[i], mu, sigma)).irregular_edge_count()\n",
    "    \n",
    "plt.plot(x, irregular)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
